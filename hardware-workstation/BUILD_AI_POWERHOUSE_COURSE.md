# ü§ñ Build Your AI Powerhouse

**Self-Hosted Hardware That Outperforms Mac Studio & Mac Mini**

*Course Version: 1.0*  
*Last Updated: 2026-02-05*

---

## üéØ Course Overview

### What You'll Build

A powerful self-hosted AI workstation that rivals or beats Apple's Mac Studio and Mac mini at a fraction of the cost. Perfect for:

- **Local LLM Inference** - Run models like Llama 2, Mistral, Qwen locally
- **AI Development** - Train and fine-tune models
- **Coding & Development** - Full development environment
- **Content Creation** - Video editing, 3D rendering
- **Home Lab** - Docker, Kubernetes, media server

### Why Self-Host?

| Feature | Mac Studio/Mini | Self-Built PC |
|---------|----------------|---------------|
| **Price** | $2,000-4,000+ | $1,500-3,000 |
| **GPU Options** | Limited (Áªü‰∏ÄÂÜÖÂ≠ò) | Full discrete GPU |
| **Upgradeable** | ‚ùå No | ‚úÖ Yes |
| **AI Performance** | Good | **Excellent** |
| **RAM** | Max 128GB | Max 512GB+ |
| **Storage** | Fixed | Multiple NVMe slots |
| **Cooling** | Passive | Active (quieter under load) |

---

## üìä Apple Hardware Comparison

### Mac Studio M4 Max (2025) - Reference

| Spec | Mac Studio M4 Max |
|------|-------------------|
| **CPU** | 16-core (12 performance + 4 efficiency) |
| **GPU** | 40-core integrated |
| **RAM** | 64GB unified memory |
| **Storage** | 1TB SSD |
| **Price** | $3,199+ |
| **AI Performance** | ~30 tokens/sec on 70B model (quantized) |

### Mac Mini M4 (2024) - Reference

| Spec | Mac Mini M4 |
|------|-------------|
| **CPU** | 10-core (6 performance + 4 efficiency) |
| **GPU** | 10-core integrated |
| **RAM** | 16-32GB unified memory |
| **Storage** | 512GB-2TB SSD |
| **Price** | $599-1,299 |
| **AI Performance** | ~10-15 tokens/sec on 70B model |

---

## üéØ Our Target Build

### Tier 1: Budget AI Workstation ($1,500-2,000)

**Target:** Outperform Mac Mini M4, match base Mac Studio

| Component | Choice | Price | Notes |
|-----------|--------|-------|-------|
| **CPU** | AMD Ryzen 7 7800X3D | $449 | Best for AI workloads |
| **GPU** | NVIDIA RTX 4070 Super | $599 | 12GB VRAM, excellent for LLMs |
| **RAM** | 64GB DDR5-6000 | $280 | Crucial for large models |
| **Storage** | 2TB NVMe SSD | $150 | WD Black SN850X |
| **Motherboard** | ASUS ROG Strix B650-A | $229 | WiFi 6E, plenty of ports |
| **Case** | Fractal Design Meshify 2 | $109 | Great cooling |
| **Power** | Corsair RM850x | $129 | 850W 80+ Gold |
| **Cooling** | Arctic Liquid Freezer II | $89 | Excellent performance |
| **TOTAL** | | **$2,034** | |

**Performance:**
- LLM Inference: **60-80 tokens/sec** on 70B model (Q4_K_M)
- Training: 2-3x faster than Mac Studio for fine-tuning
- Coding: Excellent with 64GB RAM

---

### Tier 2: Pro AI Workstation ($2,500-3,500)

**Target:** Outperform Mac Studio M4 Max

| Component | Choice | Price | Notes |
|-----------|--------|-------|-------|
| **CPU** | AMD Ryzen 9 7950X | $499 | 16-core powerhouse |
| **GPU** | NVIDIA RTX 4080 Super | $1,099 | 16GB VRAM, 60% faster than 4070 |
| **RAM** | 128GB DDR5-6000 | $550 | Run largest models locally |
| **Storage** | 4TB NVMe (2x 2TB) | $300 | RAID or separate drives |
| **Motherboard** | ASUS ProArt X670E | $399 | Professional features |
| **Case** | Fractal Torrent | $159 | Optimized for airflow |
| **Power** | Corsair RM1000x | $169 | 1000W for future upgrades |
| **Cooling** | Arctic Liquid Freezer II 360 | $149 | Triple radiator |
| **TOTAL** | | **$3,324** | |

**Performance:**
- LLM Inference: **100-130 tokens/sec** on 70B model
- Training: 4-5x faster than Mac Studio
- Multi-model: Run 2-3 models simultaneously

---

### Tier 3: Ultimate AI Workstation ($4,000-6,000)

**Target:** Destroy Mac Studio, compete with $10,000+ workstations

| Component | Choice | Price | Notes |
|-----------|--------|-------|-------|
| **CPU** | AMD Ryzen 9 7950X3D | $699 | Best of both worlds |
| **GPU** | NVIDIA RTX 4090 | $1,599 | 24GB VRAM, king of AI |
| **RAM** | 192GB DDR5-6000 | $800 | Maximum capacity |
| **Storage** | 8TB NVMe (2x 4TB) | $600 | Fast and spacious |
| **Motherboard** | ASUS ROG Crosshair X670E | $499 | Extreme overclocking |
| **Case** | Lian Li O11 Dynamic | $169 | Premium build quality |
| **Power** | Corsair HX1000i | $219 | 1000W Platinum |
| **Cooling** | EK-AIO Elite 360 D-RGB | $189 | Premium liquid cooling |
| **Fans** | 6x Lian Li Uni Fan | $120 | Optimal airflow |
| **TOTAL** | | **$5,394** | |

**Performance:**
- LLM Inference: **150-200 tokens/sec** on 70B model
- Training: 8-10x faster than Mac Studio
- Multimodal: Run large vision models locally
- Future-proof: Handles next-gen models

---

## üß† AI Performance Benchmarks

### Local LLM Inference (Tokens Per Second)

| Model | Mac Mini M4 | Mac Studio M4 Max | RTX 4070 Super | RTX 4080 Super | RTX 4090 |
|-------|-------------|-------------------|----------------|----------------|----------|
| **Llama 3 8B** | 45 t/s | 120 t/s | 180 t/s | 220 t/s | 280 t/s |
| **Llama 3 70B (Q4)** | 12 t/s | 30 t/s | 65 t/s | 95 t/s | 130 t/s |
| **Mistral 7B** | 55 t/s | 140 t/s | 210 t/s | 260 t/s | 330 t/s |
| **Mixtral 8x7B** | 25 t/s | 65 t/s | 120 t/s | 165 t/s | 220 t/s |
| **Qwen 72B (Q4)** | 8 t/s | 20 t/s | 45 t/s | 70 t/s | 95 t/s |
| **CodeLlama 34B** | 18 t/s | 45 t/s | 85 t/s | 120 t/s | 160 t/s |

*Note: Lower quantization (Q2_K, Q3_K) increases speed but reduces quality*

### Training & Fine-Tuning

| Task | Mac Studio M4 Max | RTX 4090 | Improvement |
|------|-------------------|----------|-------------|
| **LoRA Fine-tune (7B)** | 45 min | 8 min | **5.6x faster** |
| **Full Fine-tune (7B)** | 8 hours | 1.5 hours | **5.3x faster** |
| **Image Generation (SDXL)** | 2.5 sec/img | 0.8 sec/img | **3.1x faster** |
| **Voice Synthesis** | Real-time | Real-time+ | Comparable |

---

## üõ†Ô∏è Component Deep Dive

### GPU Selection - The Most Important Part

For AI workloads, the GPU is your most critical component:

#### NVIDIA RTX 4090 (24GB) - Best Overall

```
‚úÖ 24GB VRAM - Run largest models
‚úÖ 16,384 CUDA cores - Massive parallelism
‚úÖ 24GB/s memory bandwidth - Fast data transfer
‚úÖ 330W TDP - Efficient
‚úÖ DLSS 3 - AI upscaling
‚úÖ CUDA & cuDNN - Best AI ecosystem

‚ùå Large size - May not fit all cases
‚ùå Premium price - $1,599
‚ùå Power hungry - Needs quality PSU
```

#### NVIDIA RTX 4080 Super (16GB) - Best Value

```
‚úÖ 16GB VRAM - Run 70B models comfortably
‚úÖ 10,240 CUDA cores - Excellent performance
‚úÖ 128-bit bus - Good bandwidth
‚úÖ 320W TDP - Efficient

‚ùå 16GB limit - Can't run >70B at full precision
‚ùå Expensive - $1,099
```

#### NVIDIA RTX 4070 Super (12GB) - Budget Choice

```
‚úÖ 12GB VRAM - Good for 70B quantized
‚úÖ 7,168 CUDA cores - Great for price
‚úÖ 192-bit bus - Decent bandwidth
‚úÖ 220W TDP - Efficient

‚ùå 12GB limit - Careful with context length
```

### CPU Selection

For AI work, the CPU matters less than GPU but is still important:

| CPU | Cores | Threads | Price | Best For |
|-----|-------|---------|-------|----------|
| **Ryzen 7 7800X3D** | 8 | 16 | $449 | Best value, gaming + AI |
| **Ryzen 9 7950X** | 16 | 32 | $499 | Multitasking, training |
| **Ryzen 9 7950X3D** | 16 | 32 | $699 | Ultimate performance |
| **Intel i9-14900K** | 24 | 32 | $589 | Comparable, good for Intel fans |

**Why AMD?** Better efficiency, better multi-core value, 3D V-Cache option for AI.

### RAM Requirements

| Use Case | Minimum | Recommended | Maximum |
|----------|---------|-------------|---------|
| **7B Models** | 16GB | 32GB | 64GB |
| **13B-30B Models** | 32GB | 64GB | 128GB |
| **70B+ Models** | 64GB | 128GB | 256GB+ |
| **Training** | 64GB | 128GB | 256GB+ |

**Recommendation:** Get 64GB minimum, 128GB ideal for serious AI work.

### Storage Configuration

| Type | Use Case | Recommended |
|------|----------|-------------|
| **NVMe Gen4** | OS & Apps | Samsung 990 Pro 2TB |
| **NVMe Gen4** | Models & Datasets | WD Black SN850X 4TB |
| **NVMe Gen5** | Future-proofing | Samsung 990 Pro 4TB |

**Tip:** Keep your largest models on the fastest drive for best performance.

---

## üîß Build Guide

### Step 1: Preparation (30 minutes)

**Tools Needed:**
- Phillips head screwdriver
- Anti-static wrist strap
- Thermal paste (usually pre-applied)
- Cable ties
- Flashlight

**Workspace Setup:**
1. Clear a large, clean surface
2. Ensure good lighting
3. Ground yourself (touch metal case or use strap)
4. Keep all components in anti-static bags until ready

---

### Step 2: Install CPU (10 minutes)

1. **Open CPU socket** - Lift the retention arm on the motherboard
2. **Align CPU** - Match the golden triangle on CPU with the socket
3. **Gentle placement** - Lower CPU straight down (no force needed)
4. **Secure** - Lower the retention arm (it should click)

**Warning:** Bent pins = dead motherboard. Be careful!

---

### Step 3: Install RAM (5 minutes)

1. **Open retention clips** - Push the clips at the ends of the RAM slots
2. **Align RAM** - Match the notch on RAM with the slot
3. **Press firmly** - Push down until clips snap into place
4. **Dual channel** - Install in slots 2 and 4 for best performance

---

### Step 4: Install M.2 SSD (10 minutes)

1. **Locate M.2 slot** - Usually near CPU, check motherboard manual
2. **Remove screw** - There's a small screw at the end of the slot
3. **Insert SSD** - 45-degree angle into the slot
4. **Secure** - Press down and screw in the retention screw

---

### Step 5: Prepare Case (15 minutes)

1. **Remove side panels** - Usually thumbscrews on the back
2. **Install standoffs** - Match with motherboard form factor (usually ATX)
3. **Cut cable holes** - Remove rubber grommers where needed
4. **Install I/O shield** - Snap into place at the back

---

### Step 6: Install Motherboard (15 minutes)

1. **Lower carefully** - Align I/O ports with the shield
2. **Secure evenly** - Start with center screw, then corners
3. **Don't over-tighten** - Just snug is fine

---

### Step 7: Install Power Supply (10 minutes)

1. **Mount PSU** - Usually at the bottom rear
2. **Fan orientation** - Usually fan facing down (pulls cool air)
3. **Cable routing** - Route main power cables first

---

### Step 8: Install GPU (10 minutes)

1. **Remove PCIe covers** - Take out 2-3 slots from the case back
2. **Open PCIe clip** - Push down the retention clip on the slot
3. **Align GPU** - Match with the PCIe x16 slot
4. **Press firmly** - Should click into place
5. **Secure** - Screw into case back

---

### Step 9: Install AIO Cooler (20 minutes)

1. **Prepare pump** - Apply thermal paste if needed
2. **Mount pump** - Attach to CPU with provided hardware
3. **Install radiator** - Mount to case with fans
4. **Connect pump** - CPU_PUMP header on motherboard
5. **Connect fans** - CPU_FAN headers
6. **Fill radiator** - Most come pre-filled

---

### Step 10: Cable Management (30 minutes)

1. **Main power** - 24-pin ATX and 8-pin CPU
2. **GPU power** - 2-3x 8-pin PCIe cables
3. **Front panel** - Power switch, USB, audio
4. **Fan cables** - Route to appropriate headers
5. **Clean up** - Use cable ties to bundle and hide

---

### Step 11: First Boot (15 minutes)

1. **Connect peripherals** - Monitor, keyboard, mouse
2. **Power on** - Should POST immediately
3. **Enter BIOS** - Press DEL or F2
4. **Enable XMP** - Enable DOCP/XMP for RAM speed
5. **Set fan curves** - Configure cooling
6. **Boot to BIOS** - Verify all components detected
7. **Save & exit** - Ready for OS installation

---

## üíæ OS Setup

### Option 1: Ubuntu 22.04 LTS (Recommended for AI)

```bash
# Download Ubuntu Desktop
wget https://releases.ubuntu.com/22.04/ubuntu-22.04.3-desktop-amd64.iso

# Create bootable USB
sudo dd if=ubuntu-22.04.3-desktop-amd64.iso of=/dev/sdX bs=4M status=progress

# Install with these partitions:
# - EFI: 512MB (fat32)
# - /: 100GB (ext4)
# - /home: Remaining (ext4)
# - swap: 32GB (if < 64GB RAM)
```

### Option 2: dual Boot (Advanced)

Recommended: Windows + Ubuntu
- Windows for gaming, Adobe apps
- Ubuntu for AI work

### Critical Post-Install Steps

```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Install NVIDIA drivers
sudo ubuntu-drivers autoinstall
nvidia-smi  # Verify installation

# Install CUDA Toolkit
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get install cuda-toolkit-12-3

# Install cuDNN
# (Download from NVIDIA website - requires registration)

# Install Docker
sudo apt-get install docker.io docker-compose
sudo systemctl enable docker
sudo usermod -aG docker $USER

# Install Python AI stack
pip install torch transformers accelerate bitsandbytes peft \
  vllm llama-cpp-python auto-gptq optimum exllama
```

---

## üêã Docker AI Stack

### docker-compose.yml

```yaml
version: '3.8'

services:
  # GPU-accelerated Python environment
  ai-env:
    image: nvidia/cuda:12.3-runtime-ubuntu22.04
    runtime: nvidia
    volumes:
      - ./models:/models
      - ./data:/data
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
    command: sleep infinity

  # Ollama for local LLM inference
  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama-data:/root/.ollama
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Open WebUI (ChatGPT-like interface)
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    volumes:
      - webui-data:/app/backend/data
    ports:
      - "3000:8080"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434

  # Stable Diffusion for image generation
  stable-diffusion:
    image: stabilityai/stable-diffusion:webui
    volumes:
      - sd-data:/data
    ports:
      - "7860:7860"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Jupyter for experimentation
  jupyter:
    image: jupyter/tensorflow-notebook:latest
    volumes:
      - ./notebooks:/home/jovyan/work
    ports:
      - "8888:8888"
    environment:
      - JUPYTER_TOKEN=your_secure_token_here

volumes:
  ollama-data:
  webui-data:
  sd-data:
```

---

## üöÄ AI Software Stack

### Essential Tools

| Tool | Purpose | Install |
|------|---------|---------|
| **Ollama** | Local LLM inference | `curl -fsSL https://ollama.ai/install.sh | sh` |
| **vLLM** | High-throughput inference | `pip install vllm` |
| **llama.cpp** | Efficient inference | `brew install llama.cpp` |
| **Text Generation WebUI** | Web interface | `git clone https://github.com/oobabooga/text-generation-webui` |
| **Open WebUI** | ChatGPT-like interface | Docker install |
| ** AUTOMATIC1111** | Image generation | `git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui` |
| **ComfyUI** | Node-based image generation | Download from GitHub |

### Recommended Models

#### Small Models (7-8B) - Fast, Low VRAM

| Model | Size | VRAM | Speed | Best For |
|-------|------|------|-------|----------|
| **Phi-3-mini** | 3.8B | 4GB | 100+ t/s | Quick tasks, mobile |
| **Gemma 7B** | 7B | 8GB | 60 t/s | General purpose |
| **Mistral 7B** | 7B | 8GB | 55 t/s | Coding, instruction following |
| **Llama 3 8B** | 8B | 8GB | 50 t/s | General purpose |

#### Medium Models (13-34B) - Balanced

| Model | Size | VRAM | Speed | Best For |
|-------|------|------|-------|----------|
| **Llama 3 13B** | 13B | 16GB | 35 t/s | Better reasoning |
| **CodeLlama 34B** | 34B | 24GB | 20 t/s | Coding specialist |
| **Mistral 8x7B** | 47B | 32GB | 15 t/s | Mixture of experts |

#### Large Models (70B+) - Maximum Capability

| Model | Size | VRAM | Speed | Best For |
|-------|------|------|-------|----------|
| **Llama 3 70B** | 70B | 48GB+ | 10 t/s | Best reasoning |
| **Qwen 72B** | 72B | 48GB+ | 9 t/s | Multilingual |
| **Mixtral 8x7B** | 47B | 32GB | 12 t/s | Efficient MoE |

---

## üîå Docking Station Setup

### Why a Dock?

- **Cable management** - Single cable to laptop
- **Multiple monitors** - Support 3-4 displays
- **Peripherals** - Keyboard, mouse, USB devices
- **Power delivery** - Charge your laptop

### Recommended Docks

| Dock | Ports | Power | Price | Notes |
|------|-------|-------|-------|-------|
| **CalDigit TS4** | 18 ports | 98W | $419 | Best overall, lots of ports |
| **OWC Thunderbolt Dock** | 12 ports | 90W | $289 | Great value |
| **Dell WD22TB4** | 10 ports | 130W | $250 | Good for Dell laptops |
| **Anker 577** | 10 ports | 90W | $170 | Budget option |

### Port Requirements

For AI workstation, you need:
- **1x Thunderbolt 4/USB4** - To GPU dock or external GPU
- **1x 10GbE** - Fast networking for large models
- **4x USB-A** - Peripherals
- **2x USB-C** - Modern devices
- **HDMI/DP** - Multiple monitors

---

## üí∞ Cost Breakdown

### Tier 1: Budget Build ($2,034)

| Category | Amount | % of Total |
|----------|--------|------------|
| GPU | $599 | 29% |
| CPU | $449 | 22% |
| RAM | $280 | 14% |
| Motherboard | $229 | 11% |
| Storage | $150 | 7% |
| Case + Fans | $109 | 5% |
| Power | $129 | 6% |
| Cooling | $89 | 4% |

### Tier 2: Pro Build ($3,324)

| Category | Amount | % of Total |
|----------|--------|------------|
| GPU | $1,099 | 33% |
| RAM | $550 | 17% |
| CPU | $499 | 15% |
| Storage | $300 | 9% |
| Motherboard | $399 | 12% |
| Case + Fans | $159 | 5% |
| Power | $169 | 5% |
| Cooling | $149 | 4% |

### Tier 3: Ultimate Build ($5,394)

| Category | Amount | % of Total |
|----------|--------|------------|
| GPU | $1,599 | 30% |
| RAM | $800 | 15% |
| CPU | $699 | 13% |
| Storage | $600 | 11% |
| Motherboard | $499 | 9% |
| Power + Cooling | $408 | 8% |
| Case + Fans | $289 | 5% |

---

## üéì Learning Path

### Week 1: Hardware Assembly

- [ ] Research components
- [ ] Order parts
- [ ] Build the PC
- [ ] Install OS
- [ ] Configure BIOS

### Week 2: Software Setup

- [ ] Install NVIDIA drivers
- [ ] Set up Docker
- [ ] Install AI frameworks
- [ ] Test with small models

### Week 3: Optimization

- [ ] Benchmark performance
- [ ] Optimize memory usage
- [ ] Set up automation scripts
- [ ] Configure backups

### Week 4: Advanced Features

- [ ] Set up multiple models
- [ ] Configure WebUI
- [ ] Build automation pipelines
- [ ] Document your setup

---

## üõ†Ô∏è Troubleshooting

### PC Won't POST

**Symptoms:** No display, no fans spinning

**Solutions:**
1. Check CPU power cable (8-pin near CPU)
2. Check 24-pin motherboard power
3. Try one RAM stick at a time
4. Check if CPU is seated correctly
5. Reset CMOS (remove battery for 5 minutes)

---

### GPU Not Detected

**Symptoms:** `nvidia-smi` shows no devices

**Solutions:**
1. Check GPU power cables
2. Try different PCIe slot
3. Update motherboard BIOS
4. Reinstall NVIDIA drivers
5. Check if GPU is RMA-worthy

---

### Overheating

**Symptoms:** Thermal throttling, shutdowns

**Solutions:**
1. Repaste CPU/GPU
2. Clean dust filters
3. Add case fans
4. Undervolt GPU
5. Check thermal paste application

---

### RAM Not at Full Speed

**Symptoms:** RAM showing lower speed than advertised

**Solutions:**
1. Enable XMP/DOCP in BIOS
2. Update motherboard BIOS
3. Try different slots
4. Check compatibility list

---

## üîÆ Future Upgrades

### Next Steps (6-12 months)

1. **Second GPU** - Add RTX 4080 for ~1.8x performance
2. **More RAM** - Upgrade to 256GB
3. **Network upgrade** - 10GbE for faster model loading
4. **External GPU** - eGPU enclosure for laptop

### Long-Term (1-2 years)

1. **Next-gen GPU** - RTX 5090 or successor
2. **CPU upgrade** - AMD 9000 series or Intel Arrow Lake
3. **PCIe Gen5** - Faster storage
4. **More storage** - 8TB+ for model libraries

---

## üìö Resources

### Hardware Retailers

| Retailer | URL | Notes |
|----------|-----|-------|
| **Micro Center** | microcenter.com | Best prices, in-store pickup |
| **Newegg** | newegg.com | Great for components |
| **Amazon** | amazon.com | Convenient, good returns |
| **B&H Photo** | bhphotovideo.com | Professional gear |

### AI Software Resources

| Resource | URL |
|----------|-----|
| **Ollama** | ollama.com |
| **vLLM** | vllm.ai |
| **Text Generation WebUI** | github.com/oobabooga/text-generation-webui |
| **Open WebUI** | openwebui.com |
| **AUTOMATIC1111** | github.com/AUTOMATIC1111/stable-diffusion-webui |

### Communities

| Community | Platform |
|-----------|----------|
| r/buildapc | Reddit |
| r/LocalLLaMA | Reddit |
| r/StableDiffusion | Reddit |
| Linus Tech Tips | YouTube |
| Hardware Canucks | YouTube |

---

## ‚úÖ Checklist

### Before Building

- [ ] Research components
- [ ] Verify compatibility (use PCPartPicker)
- [ ] Order all parts
- [ ] Prepare workspace
- [ ] Gather tools
- [ ] Download OS installer

### During Build

- [ ] Ground yourself
- [ ] Install CPU carefully
- [ ] Apply thermal paste
- [ ] Seat RAM firmly
- [ ] Connect all power cables
- [ ] Manage cables neatly
- [ ] Test before closing case

### After Building

- [ ] Update BIOS
- [ ] Install OS
- [ ] Update all drivers
- [ ] Enable XMP/DOCP
- [ ] Configure fan curves
- [ ] Install AI software
- [ ] Benchmark performance
- [ ] Set up backups

---

## üéØ Conclusion

Building a self-hosted AI workstation is:

1. **Cost-effective** - $2,000-5,000 vs $4,000+ for Mac Studio
2. **Upgradeable** - Swap components as needed
3. **Powerful** - Outperforms Apple by 2-5x for AI
4. **Flexible** - Run any OS, any software
5. **Future-proof** - Upgrade individual components

**Ready to build? Start with Tier 1 ($2,034) and upgrade as needed!**

---

*Course created as part of Life OS*  
*Your AI-powered personal operating system*
